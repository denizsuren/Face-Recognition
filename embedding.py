import os
import cv2
from insightface.app import FaceAnalysis
import pickle
import numpy as np
import faiss
import psycopg2
import random

# PostgreSQL baÄŸlantÄ±sÄ±
DB_CONFIG = {
    "dbname": "fastapi",
    "user": "postgres",
    "password": "h12345jklj",
    "host": "localhost",
    "port": "5432"
}

# InsightFace yÃ¼z analizi modelini baÅŸlat
app = FaceAnalysis(name='buffalo_l')
app.prepare(ctx_id=-1)  # -1 = CPU, 0 = GPU

dataset_path = "images"  # Resimlerin bulunduÄŸu klasÃ¶r
embedding_list = []

print("Resimlerden embedding Ã§Ä±karÄ±lÄ±yor...")

# KlasÃ¶rdeki tÃ¼m dosyalarÄ± tara
for img_name in os.listdir(dataset_path):
    img_path = os.path.join(dataset_path, img_name)

    # Sadece resim dosyalarÄ±nÄ± iÅŸleme al
    if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
        continue

    img = cv2.imread(img_path)
    if img is None:
        print(f"Resim okunamadÄ±: {img_path}")
        continue

    # BGR -> RGB dÃ¶nÃ¼ÅŸÃ¼mÃ¼
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    faces = app.get(img_rgb)
    if len(faces) == 0:
        print(f"YÃ¼z bulunamadÄ±: {img_path}")
        continue

    for i, face in enumerate(faces):
        # InsightFace zaten normalize edilmiÅŸ embedding veriyor
        embedding = face.normed_embedding.tolist()
        embedding_list.append({
            "embedding": embedding,
            "img_name": f"{img_name}_face{i}",
            "img_path": img_path
        })
        print(f"Embedding Ã§Ä±karÄ±ldÄ±: {img_path} - yÃ¼z {i + 1}")

# Embedding'leri kaydet
with open("embeddings.pkl", "wb") as f:
    pickle.dump(embedding_list, f)

print(f"Toplam {len(embedding_list)} embedding kaydedildi.")


def create_faiss_index(embedding_file="embeddings.pkl"):
    """FAISS index oluÅŸtur - IndexIDMap olmadan, basit IndexFlatIP"""
    print("FAISS index oluÅŸturuluyor...")

    with open(embedding_file, "rb") as f:
        embedding_list = pickle.load(f)

    if len(embedding_list) == 0:
        raise ValueError("HiÃ§ embedding bulunamadÄ±! Ã–nce embedding Ã§Ä±kar.")

    # Embedding'leri numpy array'e Ã§evir
    vectors = np.array([e['embedding'] for e in embedding_list], dtype='float32')
    img_names = [e['img_name'] for e in embedding_list]

    # Basit IndexFlatIP kullan (IndexIDMap olmadan)
    dim = vectors.shape[1]
    index = faiss.IndexFlatIP(dim)  # Inner product iÃ§in normalize edilmiÅŸ embedding

    # Sequential olarak ekle (pozisyon = ID)
    index.add(vectors)

    # FAISS index'i kaydet
    faiss.write_index(index, "face_index.faiss")

    # Metadata'yÄ± kaydet - FAISS pozisyonlarÄ± ile
    metadata = {
        "img_names": img_names,
        "total_count": len(embedding_list)
    }

    with open("metadata.pkl", "wb") as f:
        pickle.dump(metadata, f)

    print(f"FAISS index oluÅŸturuldu: {index.ntotal} embedding (IndexFlatIP)")
    print(f"ID sistemi: pozisyon tabanlÄ± (0, 1, 2, ... {index.ntotal - 1})")
    return index, metadata


def init_database():
    """Database tablosunu oluÅŸtur"""
    print("Database tablosu kontrol ediliyor...")

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    # Tabloyu sil ve yeniden oluÅŸtur (temiz baÅŸlangÄ±Ã§ iÃ§in)
    cur.execute("DROP TABLE IF EXISTS passports")

    # user_id'yi INTEGER olarak oluÅŸtur (SERIAL deÄŸil)
    cur.execute("""
        CREATE TABLE passports (
            user_id INTEGER PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            passport_id VARCHAR(50) UNIQUE NOT NULL,
            flight_no VARCHAR(20),
            status VARCHAR(20) DEFAULT 'active',
            score FLOAT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    conn.commit()
    cur.close()
    conn.close()
    print("Database tablosu oluÅŸturuldu (user_id = INTEGER)")


def migrate_faiss_metadata_to_db(metadata_file="metadata.pkl"):
    """Metadata'yÄ± database'e aktar - FAISS pozisyonu = Database user_id"""
    print("Metadata database'e aktarÄ±lÄ±yor...")

    with open(metadata_file, "rb") as f:
        metadata = pickle.load(f)

    img_names = metadata["img_names"]

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    # Sequential pozisyon tabanlÄ± ID'ler (0'dan baÅŸlayarak)
    for position, img_name in enumerate(img_names):
        cur.execute("""
            INSERT INTO passports (user_id, name, passport_id, flight_no, status, score)
            VALUES (%s, %s, %s, %s, %s, %s)
            ON CONFLICT (user_id) DO NOTHING;
        """, (
            position,  # FAISS pozisyonu = database user_id
            img_name,  # name alanÄ±na img_name
            f"TR-{random.randint(100000, 999999)}",  # passport_id
            f"TK{random.randint(100, 999)}" if random.random() > 0.5 else None,  # flight_no
            'active',  # status
            round(random.uniform(0.8, 1.0), 3)  # score
        ))

    conn.commit()

    # Kontrol
    cur.execute("SELECT COUNT(*) FROM passports")
    count = cur.fetchone()[0]

    cur.execute("SELECT MIN(user_id), MAX(user_id) FROM passports")
    min_id, max_id = cur.fetchone()

    cur.close()
    conn.close()

    print(f"Migration tamamlandÄ±:")
    print(f"  - {count} kayÄ±t eklendi")
    print(f"  - user_id aralÄ±ÄŸÄ±: {min_id} - {max_id}")
    print(f"  - FAISS pozisyonu = Database user_id eÅŸleÅŸmesi saÄŸlandÄ±")


def debug_faiss_db_mapping():
    """FAISS ve DB arasÄ±ndaki mapping'i kontrol et"""
    print("\n=== MAPPING KONTROLÃœ ===")

    # FAISS index yÃ¼kle
    try:
        index = faiss.read_index("face_index.faiss")
        print(f"FAISS Total: {index.ntotal}")
    except Exception as e:
        print(f"FAISS index yÃ¼klenemedi: {e}")
        return

    # Database'den kayÄ±tlarÄ± al
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        cur.execute("SELECT user_id, name FROM passports ORDER BY user_id")
        db_records = cur.fetchall()
        cur.close()
        conn.close()
        print(f"DB Records: {len(db_records)}")
    except Exception as e:
        print(f"Database hatasÄ±: {e}")
        return

    # Metadata yÃ¼kle
    try:
        with open("metadata.pkl", "rb") as f:
            metadata = pickle.load(f)
        print(f"Metadata: {len(metadata['img_names'])}")
    except Exception as e:
        print(f"Metadata yÃ¼klenemedi: {e}")
        return

    # Ä°lk 10 kaydÄ± karÅŸÄ±laÅŸtÄ±r
    print("\nÄ°lk 10 kayÄ±t mapping kontrolÃ¼:")
    for i in range(min(10, len(db_records), len(metadata['img_names']))):
        db_id, db_name = db_records[i]
        metadata_name = metadata['img_names'][i]

        status = "âœ“" if db_id == i else "âœ—"
        print(f"{status} Pos {i}: DB_ID={db_id}, DB_Name={db_name[:30]}..., Meta_Name={metadata_name[:30]}...")

        if db_id != i:
            print(f"    âš ï¸  ID uyuÅŸmazlÄ±ÄŸÄ±: Beklenen={i}, GerÃ§ek={db_id}")

    # Ã–zet
    mapping_ok = all(db_records[i][0] == i for i in range(len(db_records)))
    print(f"\nMapping Durumu: {'âœ“ BAÅARILI' if mapping_ok else 'âœ— HATALI'}")


def verify_setup():
    """Kurulumu doÄŸrula"""
    print("\nKurulum doÄŸrulanÄ±yor...")

    # FAISS index kontrol
    try:
        index = faiss.read_index("face_index.faiss")
        print(f"âœ“ FAISS index: {index.ntotal} embedding")
        faiss_count = index.ntotal
    except Exception as e:
        print(f"âœ— FAISS index hatasÄ±: {e}")
        return False

    # Database kontrol
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM passports")
        db_count = cur.fetchone()[0]

        # ID'lerin sequential olduÄŸunu kontrol et
        cur.execute("SELECT user_id FROM passports ORDER BY user_id")
        ids = [row[0] for row in cur.fetchall()]
        expected_ids = list(range(len(ids)))

        cur.close()
        conn.close()

        print(f"âœ“ Database: {db_count} kayÄ±t")

        # ID sÄ±ralamasÄ± kontrol
        if ids == expected_ids:
            print("âœ“ Database ID'leri sequential (0, 1, 2, ...)")
        else:
            print("âœ— Database ID'leri sequential deÄŸil!")
            print(f"  Beklenen: {expected_ids[:10]}...")
            print(f"  GerÃ§ek: {ids[:10]}...")
            return False

    except Exception as e:
        print(f"âœ— Database hatasÄ±: {e}")
        return False

    # SayÄ± eÅŸleÅŸmesi kontrol
    if faiss_count == db_count:
        print("âœ“ FAISS ve Database kayÄ±t sayÄ±larÄ± eÅŸleÅŸiyor")
        return True
    else:
        print(f"âœ— KayÄ±t sayÄ±larÄ± eÅŸleÅŸmiyor! FAISS: {faiss_count}, DB: {db_count}")
        return False


if __name__ == "__main__":
    try:
        print("=== Veri HazÄ±rlama BaÅŸlatÄ±lÄ±yor ===")

        # 1. FAISS index oluÅŸtur
        index, metadata = create_faiss_index()

        # 2. Database'i hazÄ±rla
        init_database()

        # 3. Metadata'yÄ± database'e aktar
        migrate_faiss_metadata_to_db()

        # 4. Mapping'i debug et
        debug_faiss_db_mapping()

        # 5. Kurulumu doÄŸrula
        if verify_setup():
            print("\nğŸ‰ Kurulum baÅŸarÄ±yla tamamlandÄ±!")
            print("âœ“ FAISS pozisyonu = Database user_id eÅŸleÅŸmesi saÄŸlandÄ±")
            print("ArtÄ±k API'yi baÅŸlatabilir ve kamera scriptini Ã§alÄ±ÅŸtÄ±rabilirsiniz.")
        else:
            print("\nâŒ Kurulumda sorun var, lÃ¼tfen kontrol edin.")

    except Exception as e:
        print(f"âŒ Hata: {e}")
        import traceback

        traceback.print_exc()